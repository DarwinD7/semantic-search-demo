# -*- coding: utf-8 -*-
"""Streamlit-  Demo3-GreenzLabz-KallpaGreenz.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AvWmMdaOBkovCJBhjN799VKfxYTu7oBU
"""

# search_demo.py
import streamlit as st
from sentence_transformers import SentenceTransformer, util

# --- Page Configuration ---
st.set_page_config(
    page_title="Semantic Search Demo",
    page_icon="ðŸ”Ž"
)

# --- App Title and Description ---
st.title("ðŸ”Ž Greenz Labz - Semantic Search Demo")
st.write("This demo shows how our AI solves Problem 3: Ineffective and Rigid Search Functionality.")
st.write("Enter a search query below. We will show you the results from a basic Keyword Search vs. our intelligent Semantic Search.")

# --- Load AI Model ---
@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')
model = load_model()

# --- Document Database ---
corpus = [
    "The Veggie experiment on the ISS studies plant growth in microgravity.",
    "Astronauts experience significant muscle atrophy during long-duration spaceflights.",
    "Research on musculoskeletal changes in mice aboard the space station is critical.",
    "Cosmic radiation poses a significant health risk for future missions to Mars.",
    "The effect of zero-g on the human cardiovascular system is a primary focus."
]

# --- Search Logic ---
# 1. Basic Keyword Search Function
def keyword_search(query, documents):
    query_words = set(query.lower().split())
    results = []
    for doc in documents:
        if any(word in doc.lower() for word in query_words):
            results.append(doc)
    return results if results else ["No results found."]

# 2. AI-Powered Semantic Search Function
def semantic_search(query, documents):
    query_embedding = model.encode(query, convert_to_tensor=True)

    # Cache corpus embeddings for efficiency
    @st.cache_data
    def encode_corpus(documents):
        return model.encode(documents, convert_to_tensor=True)

    corpus_embeddings = encode_corpus(documents)

    cosine_scores = util.cos_sim(query_embedding, corpus_embeddings)
    best_match_index = cosine_scores.argmax()
    best_match_score = cosine_scores[0][best_match_index].item()
    best_match_doc = documents[best_match_index]

    return best_match_doc, best_match_score

# --- User Interface ---
st.markdown("---")

# Create a text input box for the user's query
user_query = st.text_input("Enter your search query (try a typo like 'rodetns bon losss in spce'):", "")

if user_query:
    st.markdown("---")

    # Create a two-column layout
    col1, col2 = st.columns(2)

    # --- Column 1: Keyword Search Results ---
    with col1:
        st.subheader("Keyword Search Results")
        keyword_results = keyword_search(user_query, corpus)
        for result in keyword_results:
            st.info(result)

    # --- Column 2: Semantic Search Results ---
    with col2:
        st.subheader("AI Semantic Search Results")
        semantic_result_doc, semantic_result_score = semantic_search(user_query, corpus)
        st.success(f"**Best Match:** {semantic_result_doc}")
        st.write(f"**Similarity Score:** {semantic_result_score:.2f}")
        st.write("*(Note: This AI understands the meaning behind your words, not just the keywords.)*")